"use strict";(self.webpackChunkkubedoop=self.webpackChunkkubedoop||[]).push([[899],{1920:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>d,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"introduction","title":"Introduction","description":"Kubedoop Data Platform is a modular, Kubernetes-native platform. Through Kubedoop,","source":"@site/docs/introduction.md","sourceDirName":".","slug":"/","permalink":"/docs/","draft":false,"unlisted":false,"editUrl":"https://github.com/zncdatadev/docs/docs/introduction.md","tags":[],"version":"current","lastUpdatedBy":"whg517","lastUpdatedAt":1732264107000,"frontMatter":{"slug":"/"},"sidebar":"docs","next":{"title":"Quick Start","permalink":"/docs/quick-start/installation"}}');var n=o(4848),a=o(8453);const i={slug:"/"},s="Introduction",d={},c=[{value:"Components",id:"components",level:2},{value:"Contributing",id:"contributing",level:2}];function l(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,n.jsx)(t.p,{children:"Kubedoop Data Platform is a modular, Kubernetes-native platform. Through Kubedoop,\nusers can quickly and easily deploy data infrastructure and algorithm infrastructure to address DataOps and MLOps requirements."}),"\n",(0,n.jsx)(t.p,{children:"Kubedoop includes mainstream data processing components such as HDFS, Hive, Kafka, Superset, etc.,\nwhile supporting data lakes and real-time data warehouses to meet the migration needs from traditional Hadoop platforms to Kubernetes platforms."}),"\n",(0,n.jsx)(t.p,{children:"Built on Kubernetes Operator technology, Kubedoop automates the lifecycle management of data processing tasks,\nincluding task creation, startup, monitoring, scheduling, restart, and scaling. Users only need to define data processing tasks through simple configuration files,\nand Kubedoop will automatically deploy the tasks to the Kubernetes cluster and manage their lifecycle."}),"\n",(0,n.jsx)(t.h2,{id:"components",children:"Components"}),"\n",(0,n.jsx)(t.p,{children:"Kubedoop Product Operators:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/airflow-operator",children:"Kubedoop Operator for Apache Airflow"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/dolphinscheduler-operator",children:"Kubedoop Operator for Apache DolphinScheduler"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/doris-operator",children:"Kubedoop Operator for Apache Doris"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/hdfs-operator",children:"Kubedoop Operator for Apache Hadoop HDFS"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/hbase-operator",children:"Kubedoop Operator for Apache HBase"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/hive-operator",children:"Kubedoop Operator for Apache Hive"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/kafka-operator",children:"Kubedoop Operator for Apache Kafka"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/kyuubi-operator",children:"Kubedoop Operator for Apache Kyuubi"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/nifi-operator",children:"Kubedoop Operator for Apache NiFi"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/spark-k8s-operator",children:"Kubedoop Operator for Apache Spark"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/superset-operator",children:"Kubedoop Operator for Apache Superset"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/trino-operator",children:"Kubedoop Operator for Trino"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/zookeeper-operator",children:"Kubedoop Operator for Apache Zookeeper"})}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"Built-in Kubedoop Operators:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/commons-operator",children:"Commons Operator"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/listener-operator",children:"Listener Operator"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/zncdatadev/secret-operator",children:"Secret Operator"})}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"contributing",children:"Contributing"}),"\n",(0,n.jsxs)(t.p,{children:["If you would like to contribute to Kubedoop, please refer to our ",(0,n.jsx)(t.a,{href:"https://kubedoop.dev/docs/developer-manual/collaboration",children:"contribution guide"})," for more information.\nWe welcome all forms of contributions, including but not limited to code, documentation, and use cases."]})]})}function p(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},8453:(e,t,o)=>{o.d(t,{R:()=>i,x:()=>s});var r=o(6540);const n={},a=r.createContext(n);function i(e){const t=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:i(e.components),r.createElement(a.Provider,{value:t},e.children)}}}]);